{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Lab 8: Learning from Images\n",
        "\n",
        "### Part 1: Butterfly Classification\n",
        "Train, Test data set for 10 butterfly species. All images are 224 X 224 X 3 in jpg format."
      ],
      "metadata": {
        "id": "jKutF41ml6S0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mounting Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "jZ2F9Y0cmIfL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import libraries\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "from sklearn.metrics import classification_report\n",
        "import numpy as np\n",
        "\n",
        "from sklearn import preprocessing\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from itertools import chain\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision.datasets import ImageFolder"
      ],
      "metadata": {
        "id": "AnAVNm8KmODr"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the image preprocessing pipeline\n",
        "Butterfly_trans = transforms.Compose([        # composes several transforms together\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor() # ToTensor() converts images to a torch.FloatTensor of shape (C x H x W) in the range [0.0, 1.0]\n",
        "])"
      ],
      "metadata": {
        "id": "UlYW3VGLmT5D"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading images and pass the images through our preprocessing pipeline\n",
        "train_butterfly10 = ImageFolder('/content/drive/MyDrive/IS675_data/Week8_data/butterfly_train_top10', transform=Butterfly_trans)\n",
        "test_butterfly10 = ImageFolder('/content/drive/MyDrive/IS675_data/Week8_data/butterfly_test_top10', transform=Butterfly_trans)"
      ],
      "metadata": {
        "id": "QWddQqnFmhmb"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Examine the number of classes\n",
        "len(train_butterfly10.classes)"
      ],
      "metadata": {
        "id": "TkkCdiEVzERB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Examine the sizes of training and test data\n",
        "print(len(train_butterfly10), len(test_butterfly10))"
      ],
      "metadata": {
        "id": "DwKvh2zszLZa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display a sample of data from test set\n",
        "class_names = ['AN 88','BLUE MORPHO','COMMON WOOD-NYMPH','MONARCH','PEACOCK','PIPEVINE SWALLOW','ULYSES','VICEROY','YELLOW SWALLOW TAIL','ZEBRA LONG WING']\n",
        "\n",
        "fig = plt.figure(figsize=(15,5))\n",
        "num_classes = 10\n",
        "for i in range(num_classes):\n",
        "    ax = fig.add_subplot(2, 5, 1 + i, xticks=[], yticks=[])\n",
        "    ax.set_title(class_names[i])\n",
        "    img = next(img for img, label in test_butterfly10 if label == i)\n",
        "    plt.imshow(img.permute(1, 2, 0))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "cdJ0d_r5zLPY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Examine the tensor of a zebra long wing image\n",
        "print(img.shape)"
      ],
      "metadata": {
        "id": "fOGaI2Vvzetx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Examine the mean and std of images in the training data\n",
        "imgs=torch.stack([img_t for img_t,label in train_butterfly10],dim=3)\n",
        "print(imgs.view(3,x1).mean(dim=1),imgs.view(3,x1).std(dim=1))"
      ],
      "metadata": {
        "id": "f7VxsFidzkJq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q1.** a) What does .view() do in the code above? b) What values can x1 take?"
      ],
      "metadata": {
        "id": "wIDY_-Zh37Kz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the image preprocessing pipeline to include normalization\n",
        "Butterfly_trans = transforms.Compose([\n",
        "    transforms.Resize((224,224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean = [0.4630, 0.4530, 0.3405], std = [0.2862, 0.2758, 0.2845])\n",
        "])"
      ],
      "metadata": {
        "id": "p0tjWxJizrL4"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading images and pass the images through our preprocessing pipeline\n",
        "train_butterfly10 = ImageFolder('/content/drive/MyDrive/IS675_data/Week8_data/butterfly_train_top10', transform=Butterfly_trans)\n",
        "test_butterfly10 = ImageFolder('/content/drive/MyDrive/IS675_data/Week8_data/butterfly_test_top10', transform=Butterfly_trans)"
      ],
      "metadata": {
        "id": "rVU2Blztzzho"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define training and testing data loader, and set batch size to 128\n",
        "train_loader_butterfly10 = torch.utils.data.DataLoader(train_butterfly10, batch_size=64, shuffle=True)\n",
        "test_loader_butterfly10 = torch.utils.data.DataLoader(test_butterfly10, batch_size=64, shuffle=False)"
      ],
      "metadata": {
        "id": "Oec_PbqDz2kw"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build a neural network on training data\n",
        "class neural_network(nn.Module):\n",
        "    def __init__(self,  in_size, hidden_size1,hidden_size2, out_size):\n",
        "        super().__init__()\n",
        "        self.network = nn.Sequential(\n",
        "          nn.Linear(in_size, hidden_size1),\n",
        "          nn.ReLU(),\n",
        "          nn.Linear(hidden_size1, hidden_size2),\n",
        "          nn.ReLU(),\n",
        "          nn.Linear(hidden_size2, out_size))\n",
        "\n",
        "    def forward(self, x):\n",
        "        x_reshape=x.view(x.shape[0],-1)\n",
        "        out = self.network(x_reshape)\n",
        "        return out.squeeze()"
      ],
      "metadata": {
        "id": "7xPjdhLUz40B"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define training loop function\n",
        "def training_loop(n_epochs, optimizer, model, loss_fn, train_loader):\n",
        "    for epoch in range(0, n_epochs):\n",
        "        # Training Phase\n",
        "        model.train()\n",
        "        loss_train = 0.0\n",
        "        for inputs, labels in train_loader:\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            loss = loss_fn(outputs, labels)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            loss_train += loss.item()\n",
        "\n",
        "        if epoch == 0 or epoch == n_epochs-1 or epoch % 1 == 0:\n",
        "            print('Epoch {}, Training loss {}'.format(epoch, loss_train / len(train_loader)))"
      ],
      "metadata": {
        "id": "q93ruxGq4iNg"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model training with hidden layers of size 128 and 64\n",
        "torch.manual_seed(0)\n",
        "model = neural_network(x2, x3, x4, x5)\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "training_loop(n_epochs = 5, optimizer = optimizer, model = model, loss_fn = loss_fn, train_loader = train_loader_butterfly10)"
      ],
      "metadata": {
        "id": "uyuE4YzH4kuQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q2.** What are the values for x2 to x5? Which ones are arbitrary?"
      ],
      "metadata": {
        "id": "hTApSDCz48Us"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q3.** Why don't we need to use softmax in the output layer of our neural_network, despite having a multi-class classification task?"
      ],
      "metadata": {
        "id": "0q0kyCQq6trh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define testing function\n",
        "def test(model, train_loader, test_loader):\n",
        "\n",
        "  # testing phase\n",
        "  model.eval()\n",
        "  predict_train = []\n",
        "  predict_test = []\n",
        "  labels_train = []\n",
        "  labels_test = []\n",
        "\n",
        "  with torch.no_grad():\n",
        "      for inputs, labels in train_loader:\n",
        "          outputs = model(inputs)\n",
        "          index_, predicted = torch.max(outputs, dim=1)\n",
        "          predict_train.append(predicted.tolist())\n",
        "          labels_train.append(labels.tolist())\n",
        "\n",
        "      for inputs, labels in test_loader:\n",
        "          outputs = model(inputs)\n",
        "          index_, predicted = torch.max(outputs, dim=1)\n",
        "          predict_test.append(predicted.tolist())\n",
        "          labels_test.append(labels.tolist())\n",
        "\n",
        "  print(\"Confusion matrix on train:\\n\",  confusion_matrix(list(chain(*labels_train)), list(chain(*predict_train)), labels=[0,1,2,3,4,5,6,7,8,9]))\n",
        "  print()\n",
        "  print(\"Classification report on train:\\n\",  classification_report(list(chain(*labels_train)), list(chain(*predict_train)), labels=[0,1,2,3,4,5,6,7,8,9]))\n",
        "  print()\n",
        "  print(\"Confusion matrix on test:\\n\",  confusion_matrix(list(chain(*labels_test)), list(chain(*predict_test)), labels=[0,1,2,3,4,5,6,7,8,9]))\n",
        "  print()\n",
        "  print(\"Classification report on test:\\n\",  classification_report(list(chain(*labels_test)), list(chain(*predict_test)), labels=[0,1,2,3,4,5,6,7,8,9]))"
      ],
      "metadata": {
        "id": "i9MPG__i40MR"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Examine evaluation results\n",
        "test(model, train_loader_butterfly10, test_loader_butterfly10)"
      ],
      "metadata": {
        "id": "MSrH6EJZ43UY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q4.** What parameters we can change in our neural net to potentially improve the performance? List every thing you can think of."
      ],
      "metadata": {
        "id": "qI9XEsFP7Y_s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Part 2: Image Classification with Fashion-MNIST\n",
        "Fashion-MNIST is a dataset consisting of a training set of 60,000 examples and a test set of 10,000 examples.\n",
        "Each example is a 28x28 grayscale image, associated with a label from 10 classes. (https://github.com/zalandoresearch/fashion-mnist)\n",
        "\n",
        "\n",
        "Label Description\n",
        "Each training and test example is assigned to one of the following labels:\n",
        "\n",
        "0 T-shirt/top,\n",
        "1 Trouser,\n",
        "2 Pullover,\n",
        "3 Dress,\n",
        "4 Coat,\n",
        "5 Sandal,\n",
        "6 Shirt,\n",
        "7 Sneaker,\n",
        "8 Bag,\n",
        "9 Ankle boot"
      ],
      "metadata": {
        "id": "JAu_0Fwg7ZVf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the image preprocessing pipeline\n",
        "MNIST_transform = transforms.Compose([transforms.ToTensor()]) # composes several transforms together"
      ],
      "metadata": {
        "id": "_uCy7jDbA8eG"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading images and pass the images through our preprocessing pipeline\n",
        "train_data = datasets.FashionMNIST('/content/drive/MyDrive/IS675_data', download = True, train = True, transform=MNIST_transform)\n",
        "test_data = datasets.FashionMNIST('/content/drive/MyDrive/IS675_data', download = True, train = False, transform=MNIST_transform)"
      ],
      "metadata": {
        "id": "7pX5jXGKBGBQ"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Examine the sizes of training and test data\n",
        "print(len(train_data), len(test_data))"
      ],
      "metadata": {
        "id": "ZwQe-zPNBfrP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display an example image for each class\n",
        "class_names = ['T-shirt/top','Trouser','Pullover','Dress','Coat','Sandal','Shirt','Sneaker','Bag','Ankle boot']\n",
        "\n",
        "fig = plt.figure(figsize=(8,3))\n",
        "num_classes = 10\n",
        "for i in range(num_classes):\n",
        "    ax = fig.add_subplot(2, 5, 1 + i, xticks=[], yticks=[])\n",
        "    ax.set_title(class_names[i])\n",
        "    img = next(img for img, label in test_data if label == i)\n",
        "    plt.imshow(np.squeeze(img), cmap='gray')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "PLf_TwUzBi_G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Examine the tensor of a Ankle boot image\n",
        "print(img.shape)\n",
        "print(img)"
      ],
      "metadata": {
        "id": "QbbUs-9WBpAJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Examine the mean and std of images in the training data\n",
        "imgs=torch.stack([img_t for img_t,label in train_data],dim=3)\n",
        "print(imgs.view(1,x6).mean(dim=1),imgs.view(1,x6).std(dim=1))"
      ],
      "metadata": {
        "id": "N9Lp-grTBtcX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q5.**  What values can x6 take?"
      ],
      "metadata": {
        "id": "iiwEKJIg8jGK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the image preprocessing pipeline to include normalization\n",
        "MNIST_trans=transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.2860],std=[0.3530])\n",
        "])"
      ],
      "metadata": {
        "id": "koH1cfwvB1X1"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading images and pass the images through our preprocessing pipeline\n",
        "train_data = datasets.FashionMNIST('/content/drive/MyDrive/IS675_data', download = True, train = True, transform=MNIST_transform)\n",
        "test_data = datasets.FashionMNIST('/content/drive/MyDrive/IS675_data', download = True, train = False, transform=MNIST_transform)"
      ],
      "metadata": {
        "id": "fEveHq1xB2et"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define training and testing data loader, and set batch size to 256\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=256, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_data, batch_size=256, shuffle=False)"
      ],
      "metadata": {
        "id": "GXtT8IgmCBYN"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build a neural network on training data\n",
        "class neural_network(nn.Module):\n",
        "    def __init__(self,  in_size, hidden_size1,hidden_size2, out_size):\n",
        "        super().__init__()\n",
        "        self.network = nn.Sequential(\n",
        "          nn.Linear(in_size, hidden_size1),\n",
        "          nn.ReLU(),\n",
        "          nn.Linear(hidden_size1, hidden_size2),\n",
        "          nn.ReLU(),\n",
        "          nn.Linear(hidden_size2, out_size))\n",
        "\n",
        "    def forward(self, x):\n",
        "        x_reshape=x.view(x.shape[0],-1)\n",
        "        out = self.network(x_reshape)\n",
        "        return out.squeeze()"
      ],
      "metadata": {
        "id": "bkYpxKCYCGCl"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define training loop function\n",
        "def training_loop(n_epochs, optimizer, model, loss_fn, train_loader):\n",
        "    for epoch in range(0, n_epochs):\n",
        "        # Training Phase\n",
        "        model.train()\n",
        "        loss_train = 0.0\n",
        "        for inputs, labels in train_loader:\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            loss = loss_fn(outputs, labels)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            loss_train += loss.item()\n",
        "\n",
        "        if epoch == 0 or epoch == n_epochs-1 or epoch % 1 == 0:\n",
        "            print('Epoch {}, Training loss {}'.format(epoch, loss_train / len(train_loader)))"
      ],
      "metadata": {
        "id": "DBk0P4wRCL4m"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q6.** Initialize the neural network with two hidden layers of size 256 and 64, choose adam optimizer and Cross Entropy loss, and train the model for 10 epochs."
      ],
      "metadata": {
        "id": "MyRf0Ymi9TWz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Q6. Model training\n",
        "torch.manual_seed(0)\n"
      ],
      "metadata": {
        "id": "ZXGIR91ZCQuP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define testing function\n",
        "def test(model, train_loader, test_loader):\n",
        "\n",
        "  # testing phase\n",
        "  model.eval()\n",
        "  predict_train = []\n",
        "  predict_test = []\n",
        "  labels_train = []\n",
        "  labels_test = []\n",
        "\n",
        "  with torch.no_grad():\n",
        "      for inputs, labels in train_loader:\n",
        "          outputs = model(inputs)\n",
        "          index_, predicted = torch.max(outputs, dim=1)\n",
        "          predict_train.append(predicted.tolist())\n",
        "          labels_train.append(labels.tolist())\n",
        "\n",
        "      for inputs, labels in test_loader:\n",
        "          outputs = model(inputs)\n",
        "          index_, predicted = torch.max(outputs, dim=1)\n",
        "          predict_test.append(predicted.tolist())\n",
        "          labels_test.append(labels.tolist())\n",
        "\n",
        "  print(\"Confusion matrix on train:\\n\",  confusion_matrix(list(chain(*labels_train)), list(chain(*predict_train)), labels=[0,1,2,3,4,5,6,7,8,9]))\n",
        "  print()\n",
        "  print(\"Classification report on train:\\n\",  classification_report(list(chain(*labels_train)), list(chain(*predict_train)), labels=[0,1,2,3,4,5,6,7,8,9]))\n",
        "  print()\n",
        "  print(\"Confusion matrix on test:\\n\",  confusion_matrix(list(chain(*labels_test)), list(chain(*predict_test)), labels=[0,1,2,3,4,5,6,7,8,9]))\n",
        "  print()\n",
        "  print(\"Classification report on test:\\n\",  classification_report(list(chain(*labels_test)), list(chain(*predict_test)), labels=[0,1,2,3,4,5,6,7,8,9]))"
      ],
      "metadata": {
        "id": "5H8mTj6uCU2N"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Examine evaluation results\n",
        "test(model, train_loader, test_loader)"
      ],
      "metadata": {
        "id": "PTJSjJ7VCtz-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Part 3: Image Classification with CIFAR-10 data\n",
        "CIFAR-10 data:CIFAR-10 consists of 60,000 tiny 32 × 32 color (RGB) images, labeled with an integer corresponding to 1 of 10 classes:\n",
        "\n",
        "0: airplane,\n",
        "1: automobile,\n",
        "2: bird,\n",
        "3: cat,\n",
        "4: deer,\n",
        "5: dog,\n",
        "6: frog,\n",
        "7: horse,\n",
        "8: ship,\n",
        "9: truck,"
      ],
      "metadata": {
        "id": "BF37TeIuC5Q4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the image preprocessing pipeline\n",
        "cifar10_transform = transforms.Compose([transforms.ToTensor()]) # composes several transforms together"
      ],
      "metadata": {
        "id": "oL-x40IuDBrt"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading images and pass the images through our preprocessing pipeline\n",
        "train_cifar10 = datasets.CIFAR10('/content/drive/MyDrive/IS675_data', train=True, download=True, transform=cifar10_transform)\n",
        "test_cifar10 = datasets.CIFAR10('/content/drive/MyDrive/IS675_data', train=False, download=True, transform=cifar10_transform)"
      ],
      "metadata": {
        "id": "8V1GoDD_DGf2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Examine the sizes of training and test data\n",
        "print(len(train_cifar10), len(test_cifar10))"
      ],
      "metadata": {
        "id": "7h5wdlqbDPbv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display an example image for each class\n",
        "class_names = ['airplane','automobile','bird','cat','deer','dog','frog','horse','ship','truck']\n",
        "\n",
        "fig = plt.figure(figsize=(8,3))\n",
        "num_classes = 10\n",
        "for i in range(num_classes):\n",
        "    ax = fig.add_subplot(2, 5, 1 + i, xticks=[], yticks=[])\n",
        "    ax.set_title(class_names[i])\n",
        "    img = next(img for img, label in train_cifar10 if label == i)\n",
        "    plt.imshow(img.permute(1, 2, 0)) # torch.Size([32, 32, 3])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "gKiZMazFDUz-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Examine the tensor of a truck image\n",
        "print(img.shape)\n",
        "print(img)"
      ],
      "metadata": {
        "id": "e5BA-t7RDbz-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Examine the mean and std of images in the training data\n",
        "imgs=torch.stack([img_t for img_t,label in train_cifar10],dim=3)\n",
        "print(imgs.shape)\n",
        "print(imgs.view(1,x7).mean(dim=1),imgs.view(1,x7).std(dim=1))"
      ],
      "metadata": {
        "id": "KjkLvG0mDknm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q7.**  What values can x7 take?"
      ],
      "metadata": {
        "id": "Oy2UGRm3E3gb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the image preprocessing pipeline to include normalization\n",
        "cifar10_trans=transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.4734],std=[0.2516])\n",
        "])"
      ],
      "metadata": {
        "id": "f8oijAfvDpXl"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading images and pass the images through our preprocessing pipeline\n",
        "train_cifar10 = datasets.CIFAR10('/content/drive/MyDrive/IS675_data', train=True, download=True, transform=cifar10_transform)\n",
        "test_cifar10 = datasets.CIFAR10('/content/drive/MyDrive/IS675_data', train=False, download=True, transform=cifar10_transform)"
      ],
      "metadata": {
        "id": "cMxIC6wpDu2O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define training and testing data loader, and set batch size to 256\n",
        "train_loader = torch.utils.data.DataLoader(train_cifar10, batch_size=256, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_cifar10, batch_size=256, shuffle=False)"
      ],
      "metadata": {
        "id": "sRMlv7yvD2G9"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build a neural network on training data\n",
        "class neural_network(nn.Module):\n",
        "    def __init__(self,  in_size, hidden_size1,hidden_size2, out_size):\n",
        "        super().__init__()\n",
        "        self.network = nn.Sequential(\n",
        "          nn.Linear(in_size, hidden_size1),\n",
        "          nn.ReLU(),\n",
        "          nn.Linear(hidden_size1, hidden_size2),\n",
        "          nn.ReLU(),\n",
        "          nn.Linear(hidden_size2, out_size))\n",
        "\n",
        "    def forward(self, x):\n",
        "        x_reshape=x.view(x.shape[0],-1)\n",
        "        out = self.network(x_reshape)\n",
        "        return out.squeeze()"
      ],
      "metadata": {
        "id": "Zs4rXwNbD5JG"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define training loop function\n",
        "def training_loop(n_epochs, optimizer, model, loss_fn, train_loader):\n",
        "    for epoch in range(0, n_epochs):\n",
        "        # Training Phase\n",
        "        model.train()\n",
        "        loss_train = 0.0\n",
        "        for inputs, labels in train_loader:\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            loss = loss_fn(outputs, labels)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            loss_train += loss.item()\n",
        "\n",
        "        if epoch == 0 or epoch == n_epochs-1 or epoch % 1 == 0:\n",
        "            print('Epoch {}, Training loss {}'.format(epoch, loss_train / len(train_loader)))"
      ],
      "metadata": {
        "id": "ofA8F92ED9uG"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q8.** Initialize the neural network with two hidden layers of size 256 and 64, choose adam optimizer and Cross Entropy loss, and train the model for 10 epochs."
      ],
      "metadata": {
        "id": "fj1Thd_QFa9J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Q7. Model training\n",
        "torch.manual_seed(0)\n"
      ],
      "metadata": {
        "id": "DnNnf9mtEBTF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define testing function\n",
        "def test(model, train_loader, test_loader):\n",
        "\n",
        "  # testing phase\n",
        "  model.eval()\n",
        "  predict_train = []\n",
        "  predict_test = []\n",
        "  labels_train = []\n",
        "  labels_test = []\n",
        "\n",
        "  with torch.no_grad():\n",
        "      for inputs, labels in train_loader:\n",
        "          outputs = model(inputs)\n",
        "          index_, predicted = torch.max(outputs, dim=1)\n",
        "          predict_train.append(predicted.tolist())\n",
        "          labels_train.append(labels.tolist())\n",
        "\n",
        "      for inputs, labels in test_loader:\n",
        "          outputs = model(inputs)\n",
        "          index_, predicted = torch.max(outputs, dim=1)\n",
        "          predict_test.append(predicted.tolist())\n",
        "          labels_test.append(labels.tolist())\n",
        "\n",
        "  print(\"Confusion matrix on train:\\n\",  confusion_matrix(list(chain(*labels_train)), list(chain(*predict_train)), labels=[0,1,2,3,4,5,6,7,8,9]))\n",
        "  print()\n",
        "  print(\"Classification report on train:\\n\",  classification_report(list(chain(*labels_train)), list(chain(*predict_train)), labels=[0,1,2,3,4,5,6,7,8,9]))\n",
        "  print()\n",
        "  print(\"Confusion matrix on test:\\n\",  confusion_matrix(list(chain(*labels_test)), list(chain(*predict_test)), labels=[0,1,2,3,4,5,6,7,8,9]))\n",
        "  print()\n",
        "  print(\"Classification report on test:\\n\",  classification_report(list(chain(*labels_test)), list(chain(*predict_test)), labels=[0,1,2,3,4,5,6,7,8,9]))"
      ],
      "metadata": {
        "id": "2BFfLZAIEFwl"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Examine evaluation results\n",
        "test(model, train_loader, test_loader)"
      ],
      "metadata": {
        "id": "sq_kN7tpEHwV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q9.** Describe the model's performance."
      ],
      "metadata": {
        "id": "V-hO-V2PGxxi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Before submitting, make sure to keep only the evaluation results logs and close any other logs.**"
      ],
      "metadata": {
        "id": "6-IRZUaUHCci"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate a html file\n",
        "!jupyter nbconvert --to html \"/content/drive/MyDrive/Colab Notebooks/IS675_lab8.ipynb\""
      ],
      "metadata": {
        "id": "hR8_sf9aEMct"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}