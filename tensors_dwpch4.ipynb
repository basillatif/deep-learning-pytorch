{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "torch.set_printoptions(edgeitems=2, threshold=50)\n",
    "import imageio\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dog Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6p/3xvwl7h96r95nst0vx2k2n3h0000gn/T/ipykernel_52166/2139723901.py:1: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
      "  img_arr = imageio.imread('./data/p1ch4/image-dog/bobby.jpg')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(720, 1280, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_arr = imageio.imread('./data/p1ch4/image-dog/bobby.jpg')\n",
    "img_arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 77,  45,  22],\n",
       "        [ 77,  45,  22],\n",
       "        [ 78,  46,  21],\n",
       "        ...,\n",
       "        [118,  78,  52],\n",
       "        [117,  77,  51],\n",
       "        [116,  76,  50]],\n",
       "\n",
       "       [[ 75,  43,  20],\n",
       "        [ 76,  44,  21],\n",
       "        [ 77,  45,  20],\n",
       "        ...,\n",
       "        [118,  78,  52],\n",
       "        [117,  77,  51],\n",
       "        [116,  76,  50]],\n",
       "\n",
       "       [[ 74,  39,  17],\n",
       "        [ 75,  40,  18],\n",
       "        [ 77,  43,  18],\n",
       "        ...,\n",
       "        [117,  80,  51],\n",
       "        [117,  78,  49],\n",
       "        [116,  77,  48]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[215, 165,  78],\n",
       "        [216, 166,  79],\n",
       "        [217, 167,  80],\n",
       "        ...,\n",
       "        [174, 121,  51],\n",
       "        [176, 123,  53],\n",
       "        [176, 123,  53]],\n",
       "\n",
       "       [[215, 165,  78],\n",
       "        [216, 166,  79],\n",
       "        [217, 167,  80],\n",
       "        ...,\n",
       "        [173, 123,  54],\n",
       "        [174, 124,  55],\n",
       "        [174, 124,  55]],\n",
       "\n",
       "       [[215, 165,  78],\n",
       "        [216, 166,  79],\n",
       "        [217, 167,  80],\n",
       "        ...,\n",
       "        [159, 109,  40],\n",
       "        [158, 107,  41],\n",
       "        [158, 107,  41]]], dtype=uint8)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# converting the image to a 3x3 array \n",
    "img_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 77,  77,  ..., 117, 116],\n",
       "         [ 75,  76,  ..., 117, 116],\n",
       "         ...,\n",
       "         [215, 216,  ..., 174, 174],\n",
       "         [215, 216,  ..., 158, 158]],\n",
       "\n",
       "        [[ 45,  45,  ...,  77,  76],\n",
       "         [ 43,  44,  ...,  77,  76],\n",
       "         ...,\n",
       "         [165, 166,  ..., 124, 124],\n",
       "         [165, 166,  ..., 107, 107]],\n",
       "\n",
       "        [[ 22,  22,  ...,  51,  50],\n",
       "         [ 20,  21,  ...,  51,  50],\n",
       "         ...,\n",
       "         [ 78,  79,  ...,  55,  55],\n",
       "         [ 78,  79,  ...,  41,  41]]], dtype=torch.uint8)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = torch.from_numpy(img_arr)\n",
    "out = img.permute(2, 0, 1)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#out\n",
    "batch_size = 3\n",
    "batch = torch.zeros(batch_size, 3, 256, 256, dtype=torch.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0, 0,  ..., 0, 0],\n",
       "          [0, 0,  ..., 0, 0],\n",
       "          ...,\n",
       "          [0, 0,  ..., 0, 0],\n",
       "          [0, 0,  ..., 0, 0]],\n",
       "\n",
       "         [[0, 0,  ..., 0, 0],\n",
       "          [0, 0,  ..., 0, 0],\n",
       "          ...,\n",
       "          [0, 0,  ..., 0, 0],\n",
       "          [0, 0,  ..., 0, 0]],\n",
       "\n",
       "         [[0, 0,  ..., 0, 0],\n",
       "          [0, 0,  ..., 0, 0],\n",
       "          ...,\n",
       "          [0, 0,  ..., 0, 0],\n",
       "          [0, 0,  ..., 0, 0]]],\n",
       "\n",
       "\n",
       "        [[[0, 0,  ..., 0, 0],\n",
       "          [0, 0,  ..., 0, 0],\n",
       "          ...,\n",
       "          [0, 0,  ..., 0, 0],\n",
       "          [0, 0,  ..., 0, 0]],\n",
       "\n",
       "         [[0, 0,  ..., 0, 0],\n",
       "          [0, 0,  ..., 0, 0],\n",
       "          ...,\n",
       "          [0, 0,  ..., 0, 0],\n",
       "          [0, 0,  ..., 0, 0]],\n",
       "\n",
       "         [[0, 0,  ..., 0, 0],\n",
       "          [0, 0,  ..., 0, 0],\n",
       "          ...,\n",
       "          [0, 0,  ..., 0, 0],\n",
       "          [0, 0,  ..., 0, 0]]],\n",
       "\n",
       "\n",
       "        [[[0, 0,  ..., 0, 0],\n",
       "          [0, 0,  ..., 0, 0],\n",
       "          ...,\n",
       "          [0, 0,  ..., 0, 0],\n",
       "          [0, 0,  ..., 0, 0]],\n",
       "\n",
       "         [[0, 0,  ..., 0, 0],\n",
       "          [0, 0,  ..., 0, 0],\n",
       "          ...,\n",
       "          [0, 0,  ..., 0, 0],\n",
       "          [0, 0,  ..., 0, 0]],\n",
       "\n",
       "         [[0, 0,  ..., 0, 0],\n",
       "          [0, 0,  ..., 0, 0],\n",
       "          ...,\n",
       "          [0, 0,  ..., 0, 0],\n",
       "          [0, 0,  ..., 0, 0]]]], dtype=torch.uint8)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6p/3xvwl7h96r95nst0vx2k2n3h0000gn/T/ipykernel_52166/1155138954.py:7: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
      "  img_arr = imageio.imread(os.path.join(data_dir, filename))\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "data_dir = './data/p1ch4/image-cats/'\n",
    "filenames = [name for name in os.listdir(data_dir)\n",
    "             if os.path.splitext(name)[-1] == '.png']\n",
    "for i, filename in enumerate(filenames):\n",
    "    img_arr = imageio.imread(os.path.join(data_dir, filename))\n",
    "    img_t = torch.from_numpy(img_arr)\n",
    "    img_t = img_t.permute(2, 0, 1)\n",
    "    img_t = img_t[:3] # <1>\n",
    "    batch[i] = img_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = batch.float()\n",
    "batch /= 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.6118, 0.5961,  ..., 0.5843, 0.6196],\n",
       "          [0.6824, 0.5255,  ..., 0.5333, 0.5412],\n",
       "          ...,\n",
       "          [0.5059, 0.5098,  ..., 0.4745, 0.4471],\n",
       "          [0.5059, 0.4824,  ..., 0.4745, 0.4706]],\n",
       "\n",
       "         [[0.5451, 0.5294,  ..., 0.5294, 0.5765],\n",
       "          [0.6275, 0.4667,  ..., 0.4784, 0.4863],\n",
       "          ...,\n",
       "          [0.4353, 0.4353,  ..., 0.4392, 0.4118],\n",
       "          [0.4353, 0.4078,  ..., 0.4314, 0.4353]],\n",
       "\n",
       "         [[0.5059, 0.4824,  ..., 0.5176, 0.5686],\n",
       "          [0.6078, 0.4314,  ..., 0.4667, 0.4745],\n",
       "          ...,\n",
       "          [0.4235, 0.4235,  ..., 0.4588, 0.4314],\n",
       "          [0.4196, 0.3843,  ..., 0.4510, 0.4549]]],\n",
       "\n",
       "\n",
       "        [[[0.7922, 0.7569,  ..., 0.0510, 0.0471],\n",
       "          [0.7804, 0.7529,  ..., 0.0549, 0.0549],\n",
       "          ...,\n",
       "          [0.2941, 0.2667,  ..., 0.1412, 0.1451],\n",
       "          [0.3333, 0.4039,  ..., 0.1451, 0.1490]],\n",
       "\n",
       "         [[0.5922, 0.5451,  ..., 0.0353, 0.0314],\n",
       "          [0.5922, 0.5490,  ..., 0.0431, 0.0431],\n",
       "          ...,\n",
       "          [0.1294, 0.1020,  ..., 0.1020, 0.1059],\n",
       "          [0.1569, 0.2275,  ..., 0.1059, 0.1098]],\n",
       "\n",
       "         [[0.2667, 0.2078,  ..., 0.0235, 0.0196],\n",
       "          [0.2627, 0.2118,  ..., 0.0235, 0.0235],\n",
       "          ...,\n",
       "          [0.0431, 0.0078,  ..., 0.0667, 0.0706],\n",
       "          [0.0745, 0.1451,  ..., 0.0706, 0.0745]]],\n",
       "\n",
       "\n",
       "        [[[0.9333, 0.9333,  ..., 0.8431, 0.8431],\n",
       "          [0.9333, 0.9333,  ..., 0.8431, 0.8431],\n",
       "          ...,\n",
       "          [0.8392, 0.8353,  ..., 0.7451, 0.7529],\n",
       "          [0.8392, 0.8353,  ..., 0.7451, 0.7529]],\n",
       "\n",
       "         [[0.7647, 0.7647,  ..., 0.6863, 0.6863],\n",
       "          [0.7647, 0.7647,  ..., 0.6863, 0.6863],\n",
       "          ...,\n",
       "          [0.5020, 0.4980,  ..., 0.4039, 0.4118],\n",
       "          [0.5020, 0.4980,  ..., 0.4039, 0.4118]],\n",
       "\n",
       "         [[0.5373, 0.5373,  ..., 0.4941, 0.4941],\n",
       "          [0.5373, 0.5373,  ..., 0.4941, 0.4941],\n",
       "          ...,\n",
       "          [0.3098, 0.3059,  ..., 0.2706, 0.2784],\n",
       "          [0.3098, 0.3059,  ..., 0.2706, 0.2824]]]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_channels = batch.shape[1]\n",
    "for c in range(n_channels):\n",
    "    mean = torch.mean(batch[:, c])\n",
    "    std = torch.std(batch[:, c])\n",
    "    batch[:, c] = (batch[:, c] - mean) / std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 3, 256, 256])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tabular Wine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 7.  ,  0.27,  0.36, ...,  0.45,  8.8 ,  6.  ],\n",
       "       [ 6.3 ,  0.3 ,  0.34, ...,  0.49,  9.5 ,  6.  ],\n",
       "       [ 8.1 ,  0.28,  0.4 , ...,  0.44, 10.1 ,  6.  ],\n",
       "       ...,\n",
       "       [ 6.5 ,  0.24,  0.19, ...,  0.46,  9.4 ,  6.  ],\n",
       "       [ 5.5 ,  0.29,  0.3 , ...,  0.38, 12.8 ,  7.  ],\n",
       "       [ 6.  ,  0.21,  0.38, ...,  0.32, 11.8 ,  6.  ]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_path = \"./data/p1ch4/tabular-wine/winequality-white.csv\"\n",
    "wineq_numpy = np.loadtxt(wine_path, dtype=np.float32, delimiter=\";\",\n",
    "                         skiprows=1)\n",
    "wineq_numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4898, 12),\n",
       " ['fixed acidity',\n",
       "  'volatile acidity',\n",
       "  'citric acid',\n",
       "  'residual sugar',\n",
       "  'chlorides',\n",
       "  'free sulfur dioxide',\n",
       "  'total sulfur dioxide',\n",
       "  'density',\n",
       "  'pH',\n",
       "  'sulphates',\n",
       "  'alcohol',\n",
       "  'quality'])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_list = next(csv.reader(open(wine_path), delimiter=';'))\n",
    "wineq_numpy.shape, col_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4898, 12]), torch.float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wineq = torch.from_numpy(wineq_numpy)\n",
    "\n",
    "wineq.shape, wineq.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 7.0000,  0.2700,  ...,  0.4500,  8.8000],\n",
       "         [ 6.3000,  0.3000,  ...,  0.4900,  9.5000],\n",
       "         ...,\n",
       "         [ 5.5000,  0.2900,  ...,  0.3800, 12.8000],\n",
       "         [ 6.0000,  0.2100,  ...,  0.3200, 11.8000]]),\n",
       " torch.Size([4898, 11]))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = wineq[:, :-1] # <1>\n",
    "data, data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([6., 6.,  ..., 7., 6.]), torch.Size([4898]))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = wineq[:, -1] # <2>\n",
    "target, target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([6, 6,  ..., 7, 6])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = wineq[:, -1].long()\n",
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0.,  ..., 0., 0.],\n",
       "        [0., 0.,  ..., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0.,  ..., 0., 0.],\n",
       "        [0., 0.,  ..., 0., 0.]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_onehot = torch.zeros(target.shape[0], 10)\n",
    "\n",
    "target_onehot.scatter_(1, target.unsqueeze(1), 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[6],\n",
       "        [6],\n",
       "        ...,\n",
       "        [7],\n",
       "        [6]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_unsqueezed = target.unsqueeze(1)\n",
    "target_unsqueezed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([6.8548e+00, 2.7824e-01, 3.3419e-01, 6.3914e+00, 4.5772e-02, 3.5308e+01,\n",
       "        1.3836e+02, 9.9403e-01, 3.1883e+00, 4.8985e-01, 1.0514e+01])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_mean = torch.mean(data, dim=0)\n",
    "data_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7.1211e-01, 1.0160e-02, 1.4646e-02, 2.5726e+01, 4.7733e-04, 2.8924e+02,\n",
       "        1.8061e+03, 8.9455e-06, 2.2801e-02, 1.3025e-02, 1.5144e+00])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_var = torch.var(data, dim=0)\n",
    "data_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.7208e-01, -8.1761e-02,  ..., -3.4915e-01, -1.3930e+00],\n",
       "        [-6.5743e-01,  2.1587e-01,  ...,  1.3422e-03, -8.2419e-01],\n",
       "        ...,\n",
       "        [-1.6054e+00,  1.1666e-01,  ..., -9.6251e-01,  1.8574e+00],\n",
       "        [-1.0129e+00, -6.7703e-01,  ..., -1.4882e+00,  1.0448e+00]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_normalized = (data - data_mean) / torch.sqrt(data_var)\n",
    "data_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4898]), torch.bool, tensor(20))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bad_indexes = target <= 3 # <1>\n",
    "bad_indexes.shape, bad_indexes.dtype, bad_indexes.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 11])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bad_data = data[bad_indexes]\n",
    "bad_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0 fixed acidity          7.60   6.89   6.73\n",
      " 1 volatile acidity       0.33   0.28   0.27\n",
      " 2 citric acid            0.34   0.34   0.33\n",
      " 3 residual sugar         6.39   6.71   5.26\n",
      " 4 chlorides              0.05   0.05   0.04\n",
      " 5 free sulfur dioxide   53.33  35.42  34.55\n",
      " 6 total sulfur dioxide 170.60 141.83 125.25\n",
      " 7 density                0.99   0.99   0.99\n",
      " 8 pH                     3.19   3.18   3.22\n",
      " 9 sulphates              0.47   0.49   0.50\n",
      "10 alcohol               10.34  10.26  11.42\n"
     ]
    }
   ],
   "source": [
    "bad_data = data[target <= 3]\n",
    "mid_data = data[(target > 3) & (target < 7)] # <1>\n",
    "good_data = data[target >= 7]\n",
    "\n",
    "bad_mean = torch.mean(bad_data, dim=0)\n",
    "mid_mean = torch.mean(mid_data, dim=0)\n",
    "good_mean = torch.mean(good_data, dim=0)\n",
    "\n",
    "for i, args in enumerate(zip(col_list, bad_mean, mid_mean, good_mean)):\n",
    "    print('{:2} {:20} {:6.2f} {:6.2f} {:6.2f}'.format(i, *args))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4898]), torch.bool, tensor(2727))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_sulfur_threshold = 141.83\n",
    "total_sulfur_data = data[:,6]\n",
    "predicted_indexes = torch.lt(total_sulfur_data, total_sulfur_threshold)\n",
    "\n",
    "predicted_indexes.shape, predicted_indexes.dtype, predicted_indexes.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4898]), torch.bool, tensor(3258))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual_indexes = target > 5\n",
    "\n",
    "actual_indexes.shape, actual_indexes.dtype, actual_indexes.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2018, 0.74000733406674, 0.6193984039287906)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_matches = torch.sum(actual_indexes & predicted_indexes).item()\n",
    "n_predicted = torch.sum(predicted_indexes).item()\n",
    "n_actual = torch.sum(actual_indexes).item()\n",
    "\n",
    "n_matches, n_matches / n_predicted, n_matches / n_actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
