{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# IS 675 Lab 9: Learning from Images with Convolutions\n",
        "\n",
        "## 1. Recap\n",
        "\n",
        "Butterfly Classification case\n",
        "\n",
        "Train, Test data set for 10 butterfly species. All images are 224 X 224 X 3 in jpg format."
      ],
      "metadata": {
        "id": "xw5JwHpOXc7q"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EK92EA7KXHEj",
        "outputId": "80cce4f0-a447-47bf-dd45-0e1a691e4841"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Mounting Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import libraries\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "from sklearn.metrics import classification_report\n",
        "import numpy as np\n",
        "from sklearn import preprocessing\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from itertools import chain\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision.datasets import ImageFolder"
      ],
      "metadata": {
        "id": "_AfGY4a5YGhY"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the image preprocessing pipeline\n",
        "Butterfly_trans = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor() # ToTensor() converts images to a torch.FloatTensor of shape (C x H x W) in the range [0.0, 1.0]\n",
        "])"
      ],
      "metadata": {
        "id": "akOGjiCsYrAY"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading images and pass the images through our preprocessing pipeline\n",
        "train_butterfly10 = ImageFolder('/content/drive/MyDrive/IS675_data/Week8_data/butterfly_train_top10', transform=Butterfly_trans)\n",
        "test_butterfly10 = ImageFolder('/content/drive/MyDrive/IS675_data/Week8_data/butterfly_test_top10', transform=Butterfly_trans)"
      ],
      "metadata": {
        "id": "uqcgpzUMYyJo"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Examine the number of classes\n",
        "print(len(train_butterfly10.classes))"
      ],
      "metadata": {
        "id": "TkkCdiEVzERB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Examine the sizes of training and test data\n",
        "print(len(train_butterfly10), len(test_butterfly10))"
      ],
      "metadata": {
        "id": "DwKvh2zszLZa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display a sample of data from test set\n",
        "class_names = ['AN 88','BLUE MORPHO','COMMON WOOD-NYMPH','MONARCH','PEACOCK','PIPEVINE SWALLOW','ULYSES','VICEROY','YELLOW SWALLOW TAIL','ZEBRA LONG WING']\n",
        "\n",
        "fig = plt.figure(figsize=(15,5))\n",
        "num_classes = 10\n",
        "for i in range(num_classes):\n",
        "    ax = fig.add_subplot(2, 5, 1 + i, xticks=[], yticks=[])\n",
        "    ax.set_title(class_names[i])\n",
        "    img = next(img for img, label in test_butterfly10 if label == i)\n",
        "    if i == 3:\n",
        "      example_img = img\n",
        "    plt.imshow(img.permute(1, 2, 0))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "cdJ0d_r5zLPY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Examine the tensor of a zebra long wing image\n",
        "print(img.shape)"
      ],
      "metadata": {
        "id": "fOGaI2Vvzetx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Convolutions"
      ],
      "metadata": {
        "id": "Qs_ESAD8ZeIp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#nn.Conv2d are the number of input features (or channels, since weâ€™re dealing with multichannel images: that is, more than one value per pixel), the number of output features, and the size of the kernel.\n",
        "conv = nn.Conv2d(3, 16, kernel_size=3)"
      ],
      "metadata": {
        "id": "gqxt1szDZdKJ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conv.weight.shape, conv.bias.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EbKKyr3OaJrP",
        "outputId": "1b7dba02-e6a1-4a31-e931-68001feb6814"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([16, 3, 3, 3]), torch.Size([16]))"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output = conv(example_img)\n",
        "example_img.shape, output.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "49qdp68saSiY",
        "outputId": "bd656ed6-7afb-44fa-a905-d7df892cf5b5"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([3, 224, 224]), torch.Size([16, 222, 222]))"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Maintain the same image size with padding\n",
        "conv = nn.Conv2d(3, 16, kernel_size=5, padding=2)"
      ],
      "metadata": {
        "id": "ZVoZk6uwbT8J"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output = conv(example_img)\n",
        "output.shape"
      ],
      "metadata": {
        "id": "nvPswU75bW-o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q1**. Usng the same input data, what is the output dimension of a convolution with 32 output channel, a 3*3 kernel, and padding = 1?"
      ],
      "metadata": {
        "id": "hz8c4Osa4vsN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###2.1. Detecting features with convolutions"
      ],
      "metadata": {
        "id": "04QbHzntbepi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(example_img[0], cmap='gray')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "2AZCv6Jvbh5I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conv = nn.Conv2d(3, 1, kernel_size=3, padding=1)\n",
        "\n",
        "with torch.no_grad():\n",
        "    conv.weight[:] = torch.tensor([[-1.0, 0.0, 1.0],\n",
        "                                   [-1.0, 0.0, 1.0],\n",
        "                                   [-1.0, 0.0, 1.0]])\n",
        "    conv.bias.zero_()"
      ],
      "metadata": {
        "id": "b318iW5rbm8_"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q2**. Why we turn off the auto grad here? What happens if we do not do it?"
      ],
      "metadata": {
        "id": "qzvXoACW6EJ6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output = conv(example_img)\n",
        "plt.imshow(output[0].detach(), cmap='gray')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "YIa3_B-JbsL5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conv = nn.Conv2d(3, 1, kernel_size=3, padding=1)\n",
        "\n",
        "with torch.no_grad():\n",
        "    conv.weight[:] = torch.tensor([[-1.0, -1.0, -1.0],\n",
        "                                   [0.0, 0.0, 0.0],\n",
        "                                   [1.0, 1.0, 1.0]])\n",
        "    conv.bias.zero_()"
      ],
      "metadata": {
        "id": "v9VjGdlHbvoY"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output = conv(example_img)\n",
        "plt.imshow(output[0].detach(), cmap='gray')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "s-hm3W1ZbzI4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###2.2. Looking Further with Depth and Pooling"
      ],
      "metadata": {
        "id": "L5rxKCcpb-Ch"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Downsample our image\n",
        "pool = nn.MaxPool2d(4)\n",
        "output = pool(img)\n",
        "output.shape"
      ],
      "metadata": {
        "id": "pv6Sj2lxb3UP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q3**. Explain why and how the image shape reduced to 56*56?\n",
        "\n",
        "**Q4**. Here we have not set any stride for pooling and it goes by default setting. What is the default stride for this pooling? What will be the size if we set the stride = 1 for the pooling?"
      ],
      "metadata": {
        "id": "0k4xH63C6ty8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.3. Model training and evaluation"
      ],
      "metadata": {
        "id": "vAaU5PgacHkp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Examine the mean and std of images in the training data\n",
        "imgs = torch.stack([img_t for img_t, label in train_butterfly10], dim=3)\n",
        "print(imgs.view(3, -1).mean(dim=1), imgs.view(3, -1).std(dim=1))"
      ],
      "metadata": {
        "id": "3Mt8PHlacMgB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q5**. What other number will work in the code above instead of -1?"
      ],
      "metadata": {
        "id": "6S7Mzs__7Hvc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the image preprocessing pipeline to include normalization\n",
        "Butterfly_trans = transforms.Compose([transforms.Resize((224, 224)), # composes several transforms together\n",
        "                                      transforms.ToTensor(),\n",
        "                                      transforms.Normalize(mean=[0.4621, 0.4528, 0.3400],std=[0.2884, 0.2767, 0.2862])\n",
        "                                      ])"
      ],
      "metadata": {
        "id": "tZdVx7dCcQfn"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading images and pass the images through our preprocessing pipeline\n",
        "train_butterfly10 = ImageFolder('/content/drive/MyDrive/IS675_data/Week8_data/butterfly_train_top10', transform=Butterfly_trans)\n",
        "test_butterfly10 = ImageFolder('/content/drive/MyDrive/IS675_data/Week8_data/butterfly_test_top10', transform=Butterfly_trans)"
      ],
      "metadata": {
        "id": "8Gezs3NCcYuJ"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define training and testing data loader, and set batch size to 128\n",
        "train_loader_butterfly10 = torch.utils.data.DataLoader(train_butterfly10, batch_size=128, shuffle=True)\n",
        "test_loader_butterfly10 = torch.utils.data.DataLoader(test_butterfly10, batch_size=128, shuffle=False)"
      ],
      "metadata": {
        "id": "9t-EqatscblI"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build a neural network on training data\n",
        "class neural_network(nn.Module):\n",
        "    def __init__(self, hidden_size1, out_size):\n",
        "        super().__init__()\n",
        "        self.network = nn.Sequential(\n",
        "          nn.Conv2d(3,8, kernel_size = 5, padding = 2), # Q6. What is the output size after this convolution?\n",
        "          nn.ReLU(),\n",
        "          nn.MaxPool2d(4), # Q7. What is the output size after this pooling?\n",
        "          nn.Conv2d(8, 4, kernel_size = 3, padding = 1), # Q8. What is the output size after this convolution?\n",
        "          nn.ReLU(),\n",
        "          nn.MaxPool2d(4), # Q9. What is the output size after this pooling?\n",
        "          nn.Flatten(), # This will make it a one dimensional vector\n",
        "          nn.Linear(X, hidden_size1), # Q10. Calculate X?\n",
        "          nn.ReLU(),\n",
        "          nn.Linear(hidden_size1, out_size))\n",
        "\n",
        "    def forward(self, x):\n",
        "      out = self.network(x)\n",
        "      return out"
      ],
      "metadata": {
        "id": "cs0rF_1Acdir"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define training loop function\n",
        "def training_loop(n_epochs, optimizer, model, loss_fn, train_loader):\n",
        "    for epoch in range(0, n_epochs):\n",
        "        # Training Phase\n",
        "        model.train()\n",
        "        loss_train = 0.0\n",
        "        for images, labels in train_loader:\n",
        "\n",
        "            outputs = model(images)\n",
        "\n",
        "            loss = loss_fn(outputs, labels)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            loss_train += loss.item()\n",
        "\n",
        "        if epoch == 0 or epoch == n_epochs-1 or epoch % 1 == 0:\n",
        "            print('Epoch {}, Training loss {}'.format(epoch, loss_train / len(train_loader)))"
      ],
      "metadata": {
        "id": "1VKcUtAacgMJ"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model training\n",
        "torch.manual_seed(0)\n",
        "model = neural_network(32, 10)\n",
        "optimizer_adam = optim.Adam(model.parameters())\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "training_loop(n_epochs= 15, optimizer= optimizer_adam, model = model, loss_fn = loss_fn, train_loader= train_loader_butterfly10)"
      ],
      "metadata": {
        "id": "ItPy6aQwcg1A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define testing function\n",
        "def test(model, train_loader, test_loader):\n",
        "\n",
        "  # testing phase\n",
        "  model.eval()\n",
        "  predict_train = []\n",
        "  predict_test = []\n",
        "  labels_train = []\n",
        "  labels_test = []\n",
        "\n",
        "  with torch.no_grad():\n",
        "      for inputs, labels in train_loader:\n",
        "          outputs = model(inputs)\n",
        "          index_, predicted = torch.max(outputs, dim=1)\n",
        "          predict_train.append(predicted.tolist())\n",
        "          labels_train.append(labels.tolist())\n",
        "\n",
        "      for inputs, labels in test_loader:\n",
        "          outputs = model(inputs)\n",
        "          index_, predicted = torch.max(outputs, dim=1)\n",
        "          predict_test.append(predicted.tolist())\n",
        "          labels_test.append(labels.tolist())\n",
        "\n",
        "  print(\"Confusion matrix on train:\\n\",  confusion_matrix(list(chain(*labels_train)), list(chain(*predict_train)), labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]))\n",
        "  print()\n",
        "  print(\"Classification report on train:\\n\",  classification_report(list(chain(*labels_train)), list(chain(*predict_train)), labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]))\n",
        "  print()\n",
        "  print(\"Confusion matrix on test:\\n\",  confusion_matrix(list(chain(*labels_test)), list(chain(*predict_test)), labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]))\n",
        "  print()\n",
        "  print(\"Classification report on test:\\n\",  classification_report(list(chain(*labels_test)), list(chain(*predict_test)), labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]))"
      ],
      "metadata": {
        "id": "QOzt7YUWcjDP"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Examine evaluation results\n",
        "test(model, train_loader_butterfly10, test_loader_butterfly10)"
      ],
      "metadata": {
        "id": "2qmLcz7XcoAH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Training on GPU\n",
        "Change the Notebook Settings in Colab: Edit-> Notebook Settings -> GPU"
      ],
      "metadata": {
        "id": "_nfRPilHcsnN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mounting Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hTnJjJ5fc5nJ",
        "outputId": "d0f9f916-bb1a-4152-c3b0-8f8f7200925e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import libraries\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "from sklearn.metrics import classification_report\n",
        "import numpy as np\n",
        "from sklearn import preprocessing\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from itertools import chain\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision.datasets import ImageFolder"
      ],
      "metadata": {
        "id": "P4BQO4ASdE9S"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = (torch.device('cuda') if torch.cuda.is_available()\n",
        "          else torch.device('cpu'))\n",
        "print(f\"Training on device {device}.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iM__EVXPc8Fh",
        "outputId": "b6bef4f9-2ae2-4626-b020-b1b22be72526"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training on device cpu.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the image preprocessing pipeline to include normalization\n",
        "Butterfly_trans = transforms.Compose([transforms.Resize((224, 224)), # composes several transforms together\n",
        "                                      transforms.ToTensor(),\n",
        "                                      transforms.Normalize(mean=[0.4621, 0.4528, 0.3400],std=[0.2884, 0.2767, 0.2862])\n",
        "                                      ])"
      ],
      "metadata": {
        "id": "JLDj6ozqdHci"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading images and pass the images through our preprocessing pipeline\n",
        "train_butterfly10 = ImageFolder('/content/drive/MyDrive/IS675_data/Week8_data/butterfly_train_top10', transform=Butterfly_trans)\n",
        "test_butterfly10 = ImageFolder('/content/drive/MyDrive/IS675_data/Week8_data/butterfly_test_top10', transform=Butterfly_trans)"
      ],
      "metadata": {
        "id": "BMZO3K-edPVq"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define training and testing data loader, and set batch size to 128\n",
        "train_loader_butterfly10 = torch.utils.data.DataLoader(train_butterfly10, batch_size=128, shuffle=True)\n",
        "test_loader_butterfly10 = torch.utils.data.DataLoader(test_butterfly10, batch_size=128, shuffle=False)"
      ],
      "metadata": {
        "id": "fS9oSdUsdLRa"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build a neural network on training data\n",
        "class neural_network(nn.Module):\n",
        "    def __init__(self,  hidden_size, out_size):\n",
        "        super().__init__()\n",
        "        self.network = nn.Sequential(\n",
        "          nn.Conv2d(3, 8, kernel_size=5, padding=2),\n",
        "          nn.ReLU(),\n",
        "          nn.MaxPool2d(4),\n",
        "          nn.Conv2d(8, 4, kernel_size=3, padding=1),\n",
        "          nn.ReLU(),\n",
        "          nn.MaxPool2d(4),\n",
        "          nn.Flatten(),\n",
        "          nn.Linear(X, hidden_size), # (-1, 32)\n",
        "          nn.ReLU(),\n",
        "          nn.Linear(hidden_size, out_size))\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.network(x)\n",
        "        return out"
      ],
      "metadata": {
        "id": "7WZzLnccdOzi"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define training loop function\n",
        "def training_loop(n_epochs, optimizer, model, loss_fn, train_loader):\n",
        "    for epoch in range(0, n_epochs):\n",
        "        # Training Phase\n",
        "        model.train()\n",
        "        loss_train = 0.0\n",
        "        for inputs, labels in train_loader:\n",
        "\n",
        "            # These two lines that move inputs and labels to the device we are training on are the only difference from our previous version.\n",
        "            inputs = inputs.to(device=device)\n",
        "            labels = labels.to(device=device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "\n",
        "            loss = loss_fn(outputs, labels)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            loss_train += loss.item()\n",
        "\n",
        "        if epoch == 0 or epoch == n_epochs-1 or epoch % 1 == 0:\n",
        "            print('Epoch {}, Training loss {}'.format(epoch, loss_train / len(train_loader)))"
      ],
      "metadata": {
        "id": "tfMAVPijdV5w"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model training\n",
        "# Model training\n",
        "torch.manual_seed(0)\n",
        "model = neural_network(32, 10).to(device=device) # Move our model (all parameters) to the GPU\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "training_loop(n_epochs = 20, optimizer = optimizer, model = model, loss_fn = loss_fn, train_loader = train_loader_butterfly10)"
      ],
      "metadata": {
        "id": "m0aEFf47dY_f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define testing function\n",
        "def test(model, train_loader, test_loader):\n",
        "\n",
        "  # testing phase\n",
        "  model.eval()\n",
        "  predict_train = []\n",
        "  predict_test = []\n",
        "  labels_train = []\n",
        "  labels_test = []\n",
        "\n",
        "  with torch.no_grad():\n",
        "      for inputs, labels in train_loader:\n",
        "          # These two lines that move inputs and labels to the device we are training on are the only difference from our previous version.\n",
        "          inputs = inputs.to(device=device)\n",
        "          labels = labels.to(device=device)\n",
        "\n",
        "          outputs = model(inputs)\n",
        "          index_, predicted = torch.max(outputs, dim=1)\n",
        "          predict_train.append(predicted.tolist())\n",
        "          labels_train.append(labels.tolist())\n",
        "\n",
        "      for inputs, labels in test_loader:\n",
        "          # These two lines that move inputs and labels to the device we are training on are the only difference from our previous version.\n",
        "          inputs = inputs.to(device=device)\n",
        "          labels = labels.to(device=device)\n",
        "\n",
        "          outputs = model(inputs)\n",
        "          index_, predicted = torch.max(outputs, dim=1)\n",
        "          predict_test.append(predicted.tolist())\n",
        "          labels_test.append(labels.tolist())\n",
        "\n",
        "  print(\"Confusion matrix on train:\\n\",  confusion_matrix(list(chain(*labels_train)), list(chain(*predict_train)), labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]))\n",
        "  print()\n",
        "  print(\"Classification report on train:\\n\",  classification_report(list(chain(*labels_train)), list(chain(*predict_train)), labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]))\n",
        "  print()\n",
        "  print(\"Confusion matrix on test:\\n\",  confusion_matrix(list(chain(*labels_test)), list(chain(*predict_test)), labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]))\n",
        "  print()\n",
        "  print(\"Classification report on test:\\n\",  classification_report(list(chain(*labels_test)), list(chain(*predict_test)), labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]))"
      ],
      "metadata": {
        "id": "yACWTpkSdccp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Examine evaluation results\n",
        "test(model, train_loader_butterfly10, test_loader_butterfly10)"
      ],
      "metadata": {
        "id": "NB-jvJPzdhTP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}