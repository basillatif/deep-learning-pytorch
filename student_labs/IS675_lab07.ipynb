{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "57VfPGEDBOeQ"
      },
      "source": [
        "#IS 675 Lab7: Recommender Systems\n",
        "##1. Data understanding\n",
        "We will use the MovieLense 1M ratings data (downloaded from http://www.grouplens.org/), which contains around 1,000,000 ratings (1-5) from 6,000 users on 4,000 movies.\n",
        "### USERS FILE DESCRIPTION\n",
        "\n",
        "User information is in the file \"**users.dat**\".\n",
        "\n",
        "Gender is denoted by a \"M\" for male and \"F\" for female\n",
        "Age is chosen from the following ranges:\n",
        "\n",
        "1: \"Under 18\"\n",
        "\n",
        "18: \"18-24\"\n",
        "\n",
        "25: \"25-34\"\n",
        "\n",
        "35: \"35-44\"\n",
        "\n",
        "45: \"45-49\"\n",
        "\n",
        "50: \"50-55\"\n",
        "\n",
        "56: \"56+\"\n",
        "\n",
        "Occupation is chosen from the following choices:\n",
        "\n",
        "0: \"other\" or not specified\n",
        "\n",
        "1: \"academic/educator\"\n",
        "\n",
        "2: \"artist\"\n",
        "\n",
        "3: \"clerical/admin\"\n",
        "\n",
        "4: \"college/grad student\"\n",
        "\n",
        "5: \"customer service\"\n",
        "\n",
        "6: \"doctor/health care\"\n",
        "\n",
        "7: \"executive/managerial\"\n",
        "\n",
        "8: \"farmer\"\n",
        "\n",
        "9: \"homemaker\"\n",
        "\n",
        "10: \"K-12 student\"\n",
        "\n",
        "11: \"lawyer\"\n",
        "\n",
        "12: \"programmer\"\n",
        "\n",
        "13: \"retired\"\n",
        "\n",
        "14: \"sales/marketing\"\n",
        "\n",
        "15: \"scientist\"\n",
        "\n",
        "16: \"self-employed\"\n",
        "\n",
        "17: \"technician/engineer\"\n",
        "\n",
        "18: \"tradesman/craftsman\"\n",
        "\n",
        "19: \"unemployed\"\n",
        "\n",
        "20: \"writer\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BblMP0caDRxg"
      },
      "source": [
        "### MOVIES FILE DESCRIPTION\n",
        "\n",
        "Movie information is in the file \"**movies.dat**\"\n",
        "\n",
        "Titles are identical to titles provided by the IMDB (including year of release)\n",
        "Genres are pipe-separated and are selected from the following genres:\n",
        "\n",
        "Action\n",
        "\n",
        "Adventure\n",
        "\n",
        "Animation\n",
        "\n",
        "Children's\n",
        "\n",
        "Comedy\n",
        "\n",
        "Crime\n",
        "\n",
        "Documentary\n",
        "\n",
        "Drama\n",
        "\n",
        "Fantasy\n",
        "\n",
        "Film-Noir\n",
        "\n",
        "Horror\n",
        "\n",
        "Musical\n",
        "\n",
        "Mystery\n",
        "\n",
        "Romance\n",
        "\n",
        "Sci-Fi\n",
        "\n",
        "Thriller\n",
        "\n",
        "War\n",
        "\n",
        "Western\n",
        "\n",
        "\n",
        "\n",
        "### RATINGS FILE DESCRIPTION\n",
        "\n",
        "All ratings are contained in the file \"**ratings.dat**\"\n",
        "\n",
        "UserIDs range between 1 and 6040\n",
        "\n",
        "MovieIDs range between 1 and 3952\n",
        "\n",
        "Ratings are made on a 5-star scale (whole-star ratings only)\n",
        "\n",
        "Unix Timestamp is represented in seconds since the epoch (the number of seconds that have elapsed since January 1, 1970)\n",
        "\n",
        "Each user has at least 20 ratings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oLYrk6slEmjR"
      },
      "source": [
        "##2. Upload and clean the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1sEWJDzRBNZ5"
      },
      "outputs": [],
      "source": [
        "# Mounting Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "89_ggAcVFTTk"
      },
      "outputs": [],
      "source": [
        "# Import needed libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import pairwise_distances\n",
        "from scipy.sparse import csr_matrix\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn import preprocessing\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from itertools import chain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hwa_RA9lFd_C"
      },
      "outputs": [],
      "source": [
        "# Read user data\n",
        "u_columns = ['user_id', 'gender', 'age', 'occupation', 'zip_code']\n",
        "users = pd.read_csv('/content/drive/MyDrive/IS675_data/users.dat', sep='::', names=u_columns, engine='python')\n",
        "users"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "auuBFJQWFxOX"
      },
      "outputs": [],
      "source": [
        "# Read movie data\n",
        "m_columns = ['movie_id', 'title', 'genre']\n",
        "movies = pd.read_csv('/content/drive/MyDrive/IS675_data/movies.dat', sep='::', names=m_columns, encoding='latin-1', engine='python')\n",
        "movies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9OIS5LvRF4bY"
      },
      "outputs": [],
      "source": [
        "# Read rating data\n",
        "r_columns = ['user_id', 'movie_id', 'rating', 'timestamp']\n",
        "ratings = pd.read_csv('/content/drive/MyDrive/IS675_data/ratings.dat', sep = '::', names=r_columns, engine='python')\n",
        "ratings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JhwatCUBGC79"
      },
      "outputs": [],
      "source": [
        "# Create a merged DataFrame\n",
        "movie_ratings = pd.merge(movies, ratings)\n",
        "MovieLense = pd.merge(movie_ratings, users)\n",
        "MovieLense"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cgzJqtucGLjU"
      },
      "outputs": [],
      "source": [
        "# Examine the first few rows\n",
        "MovieLense.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0bruQ7plGYpT"
      },
      "source": [
        "##3. Preprocess the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RCYTt66NGv0J"
      },
      "outputs": [],
      "source": [
        "# Encode movie_id and user_id\n",
        "label_encoder = preprocessing.LabelEncoder()\n",
        "ratings['movie_id'] = label_encoder.fit_transform(ratings['movie_id'])\n",
        "ratings['user_id'] = label_encoder.fit_transform(ratings['user_id'])\n",
        "ratings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sgmh3h7wG4-O"
      },
      "outputs": [],
      "source": [
        "# Sort data based on 'user_id' and 'timestamp'\n",
        "ratings = ratings.sort_values(by=['user_id', 'timestamp'])\n",
        "ratings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2yMOZdRcG_ZG"
      },
      "outputs": [],
      "source": [
        "# Partition the data into test and train\n",
        "test_data = ratings.drop_duplicates(subset=[\"user_id\"], keep='last')\n",
        "index_df = ratings.index.isin(test_data.index)\n",
        "train_data = ratings.iloc[~index_df]\n",
        "print(len(train_data), len(test_data))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tTYMISBjHUr3"
      },
      "outputs": [],
      "source": [
        "# Remove the timestamp column\n",
        "train_data = train_data[['user_id', 'movie_id', 'rating']]\n",
        "test_data = test_data[['user_id', 'movie_id', 'rating']]\n",
        "print(train_data.shape, test_data.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KLciyV2IHhXL"
      },
      "source": [
        "##4. Explore the MovieLense data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g69ms4O7HrEu"
      },
      "outputs": [],
      "source": [
        "# Total number of users\n",
        "user_num = len(ratings['user_id'].unique())\n",
        "user_num"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2YAtGq8tHtYt"
      },
      "outputs": [],
      "source": [
        "# Total number of movies\n",
        "movie_num = len(ratings['movie_id'].unique())\n",
        "movie_num"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HdTH523oHw_X"
      },
      "outputs": [],
      "source": [
        "# Rating information\n",
        "ratings['rating'].mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qNesZRHOHzt2"
      },
      "outputs": [],
      "source": [
        "# Rating distribution\n",
        "sns.countplot(x='rating', data=ratings)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ieL6Z2kVH5OJ"
      },
      "source": [
        "## 5. Collaborative Filtering Recommender Systems"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "z6ABPrbvIAAT"
      },
      "outputs": [],
      "source": [
        "# Create user-item matrix for training and testing data\n",
        "train_matrix = np.zeros([user_num, movie_num])\n",
        "for line in train_data.itertuples():\n",
        "  train_matrix[line.user_id, line.movie_id] = line.rating\n",
        "\n",
        "test_matrix = np.zeros([user_num, movie_num])\n",
        "for line in test_data.itertuples():\n",
        "  test_matrix[line.user_id, line.movie_id] = line.rating"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lGOAUB69ILlg"
      },
      "outputs": [],
      "source": [
        "# calculate the average rating for each user\n",
        "average_user_rating = np.true_divide(train_matrix.sum(1),(train_matrix!=0).sum(1))\n",
        "\n",
        "# create a train_matrix_sp represents users' preferences on different movies\n",
        "train_matrix_sp = csr_matrix(train_matrix, dtype=np.float64)\n",
        "nz = train_matrix_sp.nonzero()\n",
        "train_matrix_sp[nz] -= average_user_rating[nz[0]]\n",
        "train_matrix_sp = train_matrix_sp.toarray()\n",
        "\n",
        "# calculate the user and movie similarity\n",
        "user_similarity = pairwise_distances(train_matrix_sp)\n",
        "movie_similarity = pairwise_distances(train_matrix_sp.T)\n",
        "np.fill_diagonal(user_similarity, 0)\n",
        "np.fill_diagonal(movie_similarity, 0)\n",
        "print(user_similarity)\n",
        "print(movie_similarity)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "FRqS8zD6IRWv"
      },
      "outputs": [],
      "source": [
        "# Create a collaborative filtering algorithm\n",
        "zero_index = np.zeros(train_matrix_sp.shape)\n",
        "zero_index[nz] = 1\n",
        "def collaborative_filtering (type = 'user'):\n",
        "  if type == 'user':\n",
        "    pre_rating = average_user_rating[:, np.newaxis] + np.dot(user_similarity, train_matrix_sp)/np.dot(user_similarity, zero_index)\n",
        "  if type == 'item':\n",
        "    pre_rating = (np.dot(movie_similarity, train_matrix.T)/np.dot(movie_similarity, zero_index.T)).T\n",
        "  return pre_rating"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JS1fH0GjIXUK"
      },
      "outputs": [],
      "source": [
        "# make predictions\n",
        "user_prediction = collaborative_filtering(type='user')\n",
        "item_prediction = collaborative_filtering(type='item')\n",
        "user_prediction = np.nan_to_num(user_prediction, nan=4)\n",
        "item_prediction = np.nan_to_num(item_prediction, nan=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MV_3DSemIhzT"
      },
      "outputs": [],
      "source": [
        "# Examine the evaluation results of user-based collaborative filtering on testing data: MAE and RMSE\n",
        "MAE = mean_absolute_error(test_matrix[test_matrix!=0], user_prediction[test_matrix!=0])\n",
        "RMSE = mean_squared_error(test_matrix[test_matrix!=0], user_prediction[test_matrix!=0], squared=False)\n",
        "print(\"MAE:\", MAE)\n",
        "print(\"RMSE:\", RMSE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eHQbaWHcIvn2"
      },
      "outputs": [],
      "source": [
        "# Examine the evaluation results of item-based collaborative filtering on testing data: MAE and RMSE\n",
        "MAE = mean_absolute_error(test_matrix[test_matrix!=0], item_prediction[test_matrix!=0])\n",
        "RMSE = mean_squared_error(test_matrix[test_matrix!=0], item_prediction[test_matrix!=0], squared=False)\n",
        "print(\"MAE:\", MAE)\n",
        "print(\"RMSE:\", RMSE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ceFVLtrpIzPz"
      },
      "source": [
        "##6. Neural Collaborative Filtering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "ylMn8zblI3Vy"
      },
      "outputs": [],
      "source": [
        "# Build a neural network on training data\n",
        "class neural_network(nn.Module):\n",
        "    def __init__(self,  emb_size, hidden_size1, hidden_size2, hidden_size3, hidden_size4, out_size):\n",
        "        super().__init__()\n",
        "\n",
        "        self.user_emb = nn.Embedding(user_num, emb_size)\n",
        "        self.item_emb = nn.Embedding(movie_num, emb_size)\n",
        "\n",
        "        self.network = nn.Sequential(\n",
        "          nn.Linear(emb_size*2, hidden_size1),\n",
        "          nn.ReLU(),\n",
        "          nn.Linear(hidden_size1, hidden_size2),\n",
        "          nn.ReLU(),\n",
        "          nn.Linear(hidden_size2, hidden_size3),\n",
        "          nn.ReLU(),\n",
        "          nn.Linear(hidden_size3, hidden_size4),\n",
        "          nn.ReLU(),\n",
        "          nn.Linear(hidden_size4, out_size))\n",
        "\n",
        "    def forward(self, u_id, v_id):\n",
        "        u = self.user_emb(u_id)\n",
        "        v = self.item_emb(v_id)\n",
        "        c = torch.cat([u,v], dim = 1)\n",
        "        out = self.network(c)\n",
        "        out_sig = torch.sigmoid(out) * 5.0\n",
        "        return out_sig.squeeze()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "xwlwCsGOI_p_"
      },
      "outputs": [],
      "source": [
        "# Create tensor from pandas dataframe\n",
        "train_user_tensor=torch.tensor(train_data['user_id'].values)\n",
        "train_movie_tensor=torch.tensor(train_data['movie_id'].values)\n",
        "train_rating_tensor=torch.tensor(train_data['rating'].values)\n",
        "\n",
        "test_user_tensor=torch.tensor(test_data['user_id'].values)\n",
        "test_movie_tensor=torch.tensor(test_data['movie_id'].values)\n",
        "test_rating_tensor=torch.tensor(test_data['rating'].values)\n",
        "\n",
        "# Create tensor dataset\n",
        "train_dataset=torch.utils.data.TensorDataset(train_user_tensor.long(),train_movie_tensor.long(),train_rating_tensor.float())\n",
        "test_dataset=torch.utils.data.TensorDataset(test_user_tensor.long(),test_movie_tensor.long(),test_rating_tensor.float())\n",
        "\n",
        "# Define training and testing data loader, and set batch size to 512\n",
        "train_loader=torch.utils.data.DataLoader(train_dataset,batch_size=512,shuffle=True)\n",
        "test_loader=torch.utils.data.DataLoader(test_dataset,batch_size=512,shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "XLqQKWOjJDrm"
      },
      "outputs": [],
      "source": [
        "# Define training loop function\n",
        "def training_loop(n_epochs, optimizer, model, loss_fn, train_loader):\n",
        "    for epoch in range(0, n_epochs):\n",
        "        # Training Phase\n",
        "        model.train()\n",
        "        loss_train = 0.0\n",
        "        for user_input, movie_input, labels in train_loader: # (user_input, movie_input, labels) are from (train_user_tensor, train_movie_tensor, train_rating_tensor) in train_dataset\n",
        "                                                             # (user_input, movie_input, labels) are the inputs for each batch\n",
        "            outputs = model(user_input, movie_input) # (user_input, movie_input) correspond to the u_id, v_id, which are the inputs of the forward(self, u_id, v_id) function\n",
        "            loss = loss_fn(outputs, labels)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            loss_train += loss.item()\n",
        "\n",
        "        if epoch == 0 or epoch == n_epochs-1 or epoch % 1 == 0:\n",
        "            print('Epoch {}, Training loss {}'.format(epoch, loss_train / len(train_loader)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ENb7OUdWJJf_"
      },
      "outputs": [],
      "source": [
        "# Model training\n",
        "# %%time\n",
        "torch.manual_seed(0)\n",
        "NCF=neural_network(8,128,64,32,32,1)\n",
        "Adam_optimizer=optim.Adam(NCF.parameters(),lr=0.02)\n",
        "mse_loss=nn.MSELoss()\n",
        "\n",
        "training_loop(n_epochs=8,optimizer=Adam_optimizer,model=NCF,loss_fn=mse_loss,train_loader=train_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "jyo_jQFKJj9h"
      },
      "outputs": [],
      "source": [
        "# Define testing function\n",
        "def test(model, train_loader, test_loader):\n",
        "\n",
        "  # testing phase\n",
        "  model.eval()\n",
        "  predict_train = []\n",
        "  predict_test = []\n",
        "  label_train = []\n",
        "  label_test = []\n",
        "\n",
        "  with torch.no_grad():\n",
        "      for user_input, movie_input, labels in train_loader: # (user_input, movie_input, labels) are from (train_user_tensor, train_movie_tensor, train_rating_tensor) in train_dataset\n",
        "                                                           # (user_input, movie_input, labels) are the inputs for each batch\n",
        "          outputs = model(user_input, movie_input)         # (user_input, movie_input) correspond to the u_id, v_id, which are the inputs of the forward(self, u_id, v_id) function\n",
        "          predict_train.append(outputs.tolist())\n",
        "          label_train.append(labels.tolist())\n",
        "\n",
        "      for user_input, movie_input, labels in test_loader: # (user_input, movie_input, labels) are from (test_user_tensor, test_movie_tensor, test_rating_tensor) in test_dataset\n",
        "                                                          # (user_input, movie_input, labels) are the inputs for each batch\n",
        "          outputs = model(user_input, movie_input)        # (user_input, movie_input) correspond to the u_id, v_id, which are the inputs of the forward(self, u_id, v_id) function\n",
        "          predict_test.append(outputs.tolist())\n",
        "          label_test.append(labels.tolist())\n",
        "\n",
        "  MAE_train = mean_absolute_error(list(chain(*label_train)), list(chain(*predict_train)))\n",
        "  RMSE_train = mean_squared_error(list(chain(*label_train)), list(chain(*predict_train)), squared=False)\n",
        "\n",
        "  MAE_test = mean_absolute_error(list(chain(*label_test)), list(chain(*predict_test)))\n",
        "  RMSE_test = mean_squared_error(list(chain(*label_test)), list(chain(*predict_test)), squared=False)\n",
        "\n",
        "  print(\"Training MAE and RMSE:\", MAE_train, RMSE_train)\n",
        "  print()\n",
        "  print(\"Testing MAE and RMSE:\", MAE_test, RMSE_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "99E65czeJstq"
      },
      "outputs": [],
      "source": [
        "# Examine evaluation results\n",
        "test(model=NCF,train_loader=train_loader,test_loader=test_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E6c1KNcTeCOX"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dfgE8FxUch3S"
      },
      "source": [
        "Q1- Why did we have to use \"np.nan_to_num\" in [30]? And why number 4 is used?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4PLDOe6NdeX_"
      },
      "source": [
        "Q2- We calculated the time that the NCF takes to train the model. If you want to see the training time for the manually implemented CF, which cell's run time do you consider?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D0uq-skydGfC"
      },
      "source": [
        "Q3-Compare the results of NCF with our manually implemented CF model. Which one is faster? Which one is better? Which one do you prefer? Explain why."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WJ1JWsE9fSQL"
      },
      "source": [
        "**Close unnecessary logs before submitting to Canvas!**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PauKu5YmJ7av"
      },
      "outputs": [],
      "source": [
        "!jupyter nbconvert --to html \"/content/drive/MyDrive/Colab Notebooks/IS675_lab07.ipynb\""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
